# Evaluation of Sampling Methods for Discovering Facts from Knowledge Graph Embeddings

## Abstract
Knowledge graphs (KGs) are being used in many real-world application domains, ranging from search engines to biomedical data analysis. Even if there is a large corpus of KGs available, they are inherently incomplete due to the incompleteness of the sources based on which they were constructed. Knowledge graph embeddings (KGEs) is a very popular technique to complete KGs. However, they are only capable of answering true or false to a given fact. Thus, users need to provide a concrete query or some test data. Unfortunately, such queries or data are not always available.  There are cases where one wants to discover all (or as many as possible) missing facts from an input KG given a KGE model.  To do so, one should provide to the KGE model candidate facts consisting of the complement of the input KG.  This can be infeasible even for small graphs simply due to the size of the complement graph. In this paper, we define the problem of discovering missing facts from a given KGE model and refer to it as fact discovery. We study sampling methods to get candidate facts and then using KGEs to retrieve the most plausible ones. We extensively evaluate different existing sampling methods and provide guidelines on when each one of them is most suitable. We also discuss the challenges and limitations that we encountered when investigating the different techniques. With these insights, we hope to shed light and attract more researchers to work on this unexplored direction.

## Model Training
Our experiments include 4 datasets, 5 KG embeddings, resulting in a total of 20 different KGE models. We trained our models using the [LibKGE library](https://github.com/uma-pi1/kge#results-and-pretrained-models). We used pre-trained model already provided on the library's github page and trained and optimized the rest on our own setup as per the instructions in the [ICLR2020](https://github.com/uma-pi1/kge-iclr20) github page. The config files required for the hyperparameter optimization can be found in [config_files](config_files/).

## Fact Discovery
We adopted the discovery algorithm from [Ampligraph](https://docs.ampligraph.org/en/1.4.0/generated/ampligraph.discovery.discover_facts.html) and introduced some minor changes to suit our LibKGE-based experimental code. The original code of Ampligraph deals with the fact candidate generation and evaluation sequentially in a single function call. In contrast, our [discover.py](scripts/discover.py) first generates fact candidates from all datasets using all of the discovery strategies. Then we run [run_eval.sh](scripts/run_eval.sh) to evaluate and filter the fact candidates.

The fact candidates and discovered facts frmo our experiments can be found in [fact_candidates](fact_candidates/) and [discovered_facts](discovered_facts/) respectively.


